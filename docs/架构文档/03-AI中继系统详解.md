# New API AI 中继系统详解

## 中继系统概述

AI 中继系统是 New API 的核心功能，负责将客户端的 API 请求转发到上游 AI 提供商，并处理响应。系统支持 39+ 个 AI 提供商，提供统一的 OpenAI 兼容接口。

## 系统架构

```
客户端请求
    ↓
Relay Router (路由识别)
    ↓
Auth Middleware (认证)
    ↓
Distributor Middleware (渠道分发)
    ↓
Channel Adaptor (格式转换)
    ↓
HTTP Client (发送请求)
    ↓
上游 AI 提供商
    ↓
Response Handler (响应处理)
    ↓
Billing Service (计费)
    ↓
返回客户端
```

## 支持的 AI 提供商

### 1. 国际提供商 (20+)

| 提供商 | 渠道类型 | 支持的端点 |
|--------|---------|-----------|
| OpenAI | 1 | Chat, Embeddings, Audio, Images, Moderations, Realtime |
| Claude (Anthropic) | 2 | Messages, Messages Streaming |
| Azure OpenAI | 3 | Chat, Embeddings, Audio, Images |
| Google Gemini | 4 | GenerateContent, StreamGenerateContent |
| AWS Bedrock | 5 | Chat, Embeddings |
| PaLM | 6 | Chat, Embeddings |
| Mistral | 7 | Chat, Embeddings |
| OpenRouter | 8 | Chat, Embeddings |
| Perplexity | 9 | Chat |
| Cohere | 10 | Chat, Embeddings, Rerank |
| Cloudflare | 11 | Chat |
| Vertex AI | 12 | Chat, Embeddings |
| Replicate | 13 | Predictions |
| Ollama | 14 | Chat, Embeddings |
| xAI (Grok) | 15 | Chat, Responses |
| Jina | 16 | Embeddings, Rerank |

### 2. 国内提供商 (15+)

| 提供商 | 渠道类型 | 支持的端点 |
|--------|---------|-----------|
| 百度文心 | 17 | Chat, Embeddings |
| 阿里通义 | 18 | Chat, Embeddings |
| 腾讯混元 | 19 | Chat |
| 讯飞星火 | 20 | Chat |
| 智谱清言 | 21 | Chat, Embeddings |
| DeepSeek | 22 | Chat |
| Moonshot | 23 | Chat |
| 零一万物 | 24 | Chat |
| MiniMax | 25 | Chat |
| 360智脑 | 26 | Chat |
| 火山引擎 | 27 | Chat |
| SiliconFlow | 28 | Chat |
| MokaAI | 29 | Chat |
| Coze | 30 | Chat |
| Dify | 31 | Chat |

### 3. 特殊服务 (4+)

| 服务 | 渠道类型 | 功能 |
|------|---------|------|
| Midjourney | 32 | 图像生成 |
| Suno | 33 | 音乐生成 |
| Codex | 34 | 代码生成 |
| 极梦 | 35 | 图像生成 |

## 中继模式 (Relay Mode)

系统根据请求路径和方法识别中继模式：

```go
const (
    RelayModeUnknown = iota
    RelayModeChatCompletions      // /v1/chat/completions
    RelayModeCompletions          // /v1/completions
    RelayModeEmbeddings           // /v1/embeddings
    RelayModeImagesGenerations    // /v1/images/generations
    RelayModeEdits                // /v1/images/edits
    RelayModeAudioSpeech          // /v1/audio/speech
    RelayModeAudioTranscription   // /v1/audio/transcriptions
    RelayModeAudioTranslation     // /v1/audio/translations
    RelayModeModerations          // /v1/moderations
    RelayModeRealtime             // /v1/realtime (WebSocket)

    // Claude
    RelayModeClaude               // /v1/messages

    // Gemini
    RelayModeGemini               // /v1beta/models/*

    // Midjourney
    RelayModeMidjourneyImagine    // /mj/imagine
    RelayModeMidjourneyUpscale    // /mj/upscale
    RelayModeMidjourneyVary       // /mj/vary
    // ... 更多 MJ 模式

    // Suno
    RelayModeSunoGenerate         // /suno/generate
    RelayModeSunoFetch            // /suno/fetch

    // Video
    RelayModeVideoSubmit          // /v1/videos
    RelayModeVideoFetchByID       // /v1/videos/{id}
)
```

## 渠道分发流程

### 1. Distributor Middleware

`middleware/distributor.go` 是渠道分发的核心：

```go
func Distribute() func(c *gin.Context) {
    return func(c *gin.Context) {
        // 1. 解析请求模型
        modelRequest, shouldSelectChannel, err := getModelRequest(c)

        // 2. 检查令牌模型限制
        if modelLimitEnable {
            // 验证令牌是否有权访问该模型
        }

        // 3. 选择渠道
        if shouldSelectChannel {
            // 3.1 检查渠道亲和性（优先使用最近成功的渠道）
            if preferredChannelID, found := service.GetPreferredChannelByAffinity(...) {
                channel = preferred
            }

            // 3.2 随机选择可用渠道
            if channel == nil {
                channel, selectGroup, err = service.CacheGetRandomSatisfiedChannel(...)
            }
        }

        // 4. 设置渠道上下文
        SetupContextForSelectedChannel(c, channel, modelRequest.Model)

        // 5. 执行请求
        c.Next()

        // 6. 记录渠道亲和性（成功时）
        if channel != nil && c.Writer.Status() < 400 {
            service.RecordChannelAffinity(c, channel.Id)
        }
    }
}
```

### 2. 渠道选择策略

#### 2.1 渠道亲和性 (Channel Affinity)

系统会记住每个用户最近成功使用的渠道，优先使用这些渠道：

```go
// 记录成功的渠道
func RecordChannelAffinity(c *gin.Context, channelId int) {
    userId := c.GetInt("user_id")
    group := c.GetString("using_group")
    model := c.GetString("original_model")

    key := fmt.Sprintf("affinity:%d:%s:%s", userId, group, model)
    redis.Set(key, channelId, 1*time.Hour)
}

// 获取优先渠道
func GetPreferredChannelByAffinity(c *gin.Context, model, group string) (int, bool) {
    userId := c.GetInt("user_id")
    key := fmt.Sprintf("affinity:%d:%s:%s", userId, group, model)

    channelId, err := redis.Get(key).Int()
    return channelId, err == nil
}
```

#### 2.2 随机选择算法

```go
func CacheGetRandomSatisfiedChannel(param *RetryParam) (*model.Channel, string, error) {
    // 1. 获取所有可用渠道
    channels := model.GetChannelsByGroupModel(param.TokenGroup, param.ModelName)

    // 2. 过滤已失败的渠道
    if param.Retry != nil && *param.Retry > 0 {
        channels = filterFailedChannels(channels, param.FailedChannelIds)
    }

    // 3. 按权重和优先级排序
    channels = sortChannelsByWeightAndPriority(channels)

    // 4. 加权随机选择
    totalWeight := 0
    for _, ch := range channels {
        totalWeight += int(*ch.Weight)
    }

    randomWeight := rand.Intn(totalWeight)
    for _, ch := range channels {
        randomWeight -= int(*ch.Weight)
        if randomWeight < 0 {
            return ch, selectGroup, nil
        }
    }

    return nil, "", errors.New("no available channel")
}
```

### 3. 渠道上下文设置

```go
func SetupContextForSelectedChannel(c *gin.Context, channel *model.Channel, modelName string) {
    // 设置渠道基本信息
    c.Set("channel_id", channel.Id)
    c.Set("channel_name", channel.Name)
    c.Set("channel_type", channel.Type)
    c.Set("channel_base_url", channel.GetBaseURL())

    // 获取下一个可用的 Key
    key, index, err := channel.GetNextEnabledKey()
    c.Set("channel_key", key)

    // 多 Key 模式
    if channel.ChannelInfo.IsMultiKey {
        c.Set("channel_is_multi_key", true)
        c.Set("channel_multi_key_index", index)
    }

    // 设置高级配置
    c.Set("channel_model_mapping", channel.GetModelMapping())
    c.Set("channel_param_override", channel.GetParamOverride())
    c.Set("channel_header_override", channel.GetHeaderOverride())
    c.Set("channel_status_code_mapping", channel.GetStatusCodeMapping())

    // 特定渠道配置
    switch channel.Type {
    case constant.ChannelTypeAzure:
        c.Set("api_version", channel.Other)
    case constant.ChannelTypeGemini:
        c.Set("api_version", channel.Other)
    // ... 其他渠道
    }
}
```

## 渠道适配器 (Channel Adaptor)

### 1. 适配器接口

每个渠道都实现了统一的适配器接口：

```go
type Adaptor interface {
    // 初始化
    Init(info *relaycommon.RelayInfo)

    // 请求转换
    ConvertRequest(c *gin.Context, relayMode int, request *dto.GeneralOpenAIRequest) (any, error)

    // 执行请求
    DoRequest(c *gin.Context, info *relaycommon.RelayInfo, requestBody io.Reader) (*http.Response, error)

    // 响应处理
    DoResponse(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo) (usage *dto.Usage, err *types.OpenAIErrorWithStatusCode)

    // 获取模型列表
    GetModelList() []string

    // 获取渠道名称
    GetChannelName() string
}
```

### 2. OpenAI 适配器示例

```go
type Adaptor struct {
    ChannelType    int
    ResponseFormat string
}

func (a *Adaptor) Init(info *relaycommon.RelayInfo) {
    a.ChannelType = info.ChannelType
}

func (a *Adaptor) ConvertRequest(c *gin.Context, relayMode int, request *dto.GeneralOpenAIRequest) (any, error) {
    // OpenAI 格式不需要转换
    return request, nil
}

func (a *Adaptor) DoRequest(c *gin.Context, info *relaycommon.RelayInfo, requestBody io.Reader) (*http.Response, error) {
    // 构建请求
    req, err := http.NewRequest("POST", info.BaseURL+info.RequestPath, requestBody)
    req.Header.Set("Authorization", "Bearer "+info.ApiKey)
    req.Header.Set("Content-Type", "application/json")

    // 发送请求
    return service.GetHttpClient().Do(req)
}

func (a *Adaptor) DoResponse(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo) (*dto.Usage, error) {
    if info.IsStream {
        return a.handleStreamResponse(c, resp, info)
    }
    return a.handleNonStreamResponse(c, resp, info)
}
```

### 3. Claude 适配器示例

Claude 使用不同的 API 格式，需要转换：

```go
func (a *Adaptor) ConvertClaudeRequest(c *gin.Context, info *relaycommon.RelayInfo, request *dto.ClaudeRequest) (any, error) {
    // Claude → OpenAI 格式转换
    openaiRequest := &dto.GeneralOpenAIRequest{
        Model:    request.Model,
        Messages: convertClaudeMessages(request.Messages),
        Stream:   request.Stream,
        MaxTokens: request.MaxTokens,
    }

    // 处理 system prompt
    if request.System != "" {
        openaiRequest.Messages = append([]dto.Message{
            {Role: "system", Content: request.System},
        }, openaiRequest.Messages...)
    }

    return openaiRequest, nil
}

func convertClaudeMessages(claudeMessages []dto.ClaudeMessage) []dto.Message {
    messages := make([]dto.Message, 0, len(claudeMessages))
    for _, msg := range claudeMessages {
        messages = append(messages, dto.Message{
            Role:    msg.Role,
            Content: convertClaudeContent(msg.Content),
        })
    }
    return messages
}
```

### 4. Gemini 适配器示例

Gemini 使用完全不同的 API 结构：

```go
func (a *Adaptor) ConvertGeminiRequest(c *gin.Context, info *relaycommon.RelayInfo, request *dto.GeminiChatRequest) (any, error) {
    // Gemini → OpenAI 格式转换
    openaiRequest := &dto.GeneralOpenAIRequest{
        Model:    request.Model,
        Messages: convertGeminiContents(request.Contents),
        Stream:   request.GenerationConfig.Stream,
    }

    // 转换生成配置
    if request.GenerationConfig != nil {
        openaiRequest.MaxTokens = request.GenerationConfig.MaxOutputTokens
        openaiRequest.Temperature = request.GenerationConfig.Temperature
        openaiRequest.TopP = request.GenerationConfig.TopP
    }

    return openaiRequest, nil
}

func convertGeminiContents(contents []dto.GeminiContent) []dto.Message {
    messages := make([]dto.Message, 0, len(contents))
    for _, content := range contents {
        messages = append(messages, dto.Message{
            Role:    convertGeminiRole(content.Role),
            Content: convertGeminiParts(content.Parts),
        })
    }
    return messages
}
```

## 流式响应处理

### 1. SSE (Server-Sent Events) 格式

OpenAI 使用 SSE 格式传输流式响应：

```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"content":" world"},"finish_reason":null}]}

data: [DONE]
```

### 2. 流式响应处理器

```go
func (a *Adaptor) handleStreamResponse(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo) (*dto.Usage, error) {
    // 设置响应头
    c.Header("Content-Type", "text/event-stream")
    c.Header("Cache-Control", "no-cache")
    c.Header("Connection", "keep-alive")

    // 创建扫描器
    scanner := bufio.NewScanner(resp.Body)
    scanner.Split(func(data []byte, atEOF bool) (advance int, token []byte, err error) {
        // 自定义分割函数，按 "data: " 分割
        if atEOF && len(data) == 0 {
            return 0, nil, nil
        }
        if i := bytes.Index(data, []byte("\n\n")); i >= 0 {
            return i + 2, data[0:i], nil
        }
        if atEOF {
            return len(data), data, nil
        }
        return 0, nil, nil
    })

    // 逐块处理
    var usage *dto.Usage
    for scanner.Scan() {
        data := scanner.Bytes()

        // 跳过空行和注释
        if len(data) == 0 || bytes.HasPrefix(data, []byte(":")) {
            continue
        }

        // 移除 "data: " 前缀
        if bytes.HasPrefix(data, []byte("data: ")) {
            data = data[6:]
        }

        // 检查结束标记
        if bytes.Equal(data, []byte("[DONE]")) {
            c.SSEvent("", " [DONE]")
            c.Writer.Flush()
            break
        }

        // 解析 JSON
        var chunk dto.ChatCompletionChunk
        if err := json.Unmarshal(data, &chunk); err != nil {
            continue
        }

        // 提取 usage 信息
        if chunk.Usage != nil {
            usage = chunk.Usage
        }

        // 转发给客户端
        c.SSEvent("", string(data))
        c.Writer.Flush()
    }

    return usage, nil
}
```

### 3. 非流式响应处理器

```go
func (a *Adaptor) handleNonStreamResponse(c *gin.Context, resp *http.Response, info *relaycommon.RelayInfo) (*dto.Usage, error) {
    // 读取响应体
    body, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, err
    }

    // 解析响应
    var response dto.OpenAIResponse
    if err := json.Unmarshal(body, &response); err != nil {
        return nil, err
    }

    // 提取 usage
    usage := response.Usage

    // 返回给客户端
    c.JSON(resp.StatusCode, response)

    return usage, nil
}
```

## 请求重试机制

### 1. 重试策略

```go
func RelayWithRetry(c *gin.Context, relayMode int) {
    maxRetry := 3
    for retry := 0; retry < maxRetry; retry++ {
        // 执行请求
        err := doRelay(c, relayMode)

        // 成功则返回
        if err == nil {
            return
        }

        // 检查是否可重试
        if !isRetryableError(err) {
            return
        }

        // 记录失败的渠道
        failedChannelId := c.GetInt("channel_id")
        c.Set("failed_channel_ids", append(
            c.GetIntSlice("failed_channel_ids"),
            failedChannelId,
        ))

        // 重新选择渠道
        channel, _, err := service.CacheGetRandomSatisfiedChannel(&service.RetryParam{
            Ctx:              c,
            ModelName:        c.GetString("original_model"),
            TokenGroup:       c.GetString("using_group"),
            Retry:            &retry,
            FailedChannelIds: c.GetIntSlice("failed_channel_ids"),
        })

        if err != nil {
            return
        }

        // 设置新渠道
        SetupContextForSelectedChannel(c, channel, c.GetString("original_model"))
    }
}

func isRetryableError(err error) bool {
    // 429 Too Many Requests
    // 500 Internal Server Error
    // 502 Bad Gateway
    // 503 Service Unavailable
    // 504 Gateway Timeout
    statusCode := getStatusCode(err)
    return statusCode == 429 || statusCode >= 500
}
```

## Token 计数

### 1. Token 计数器

系统使用 tiktoken 库进行 Token 计数：

```go
func CountTokens(model string, messages []dto.Message) (int, error) {
    // 获取编码器
    encoder, err := getEncoder(model)
    if err != nil {
        return 0, err
    }

    // 计算 Token 数
    totalTokens := 0
    for _, msg := range messages {
        // 消息开销（角色、分隔符等）
        totalTokens += 4

        // 角色 Token
        totalTokens += len(encoder.Encode(msg.Role, nil, nil))

        // 内容 Token
        switch content := msg.Content.(type) {
        case string:
            totalTokens += len(encoder.Encode(content, nil, nil))
        case []interface{}:
            for _, part := range content {
                if textPart, ok := part.(map[string]interface{}); ok {
                    if text, ok := textPart["text"].(string); ok {
                        totalTokens += len(encoder.Encode(text, nil, nil))
                    }
                }
            }
        }
    }

    // 响应开销
    totalTokens += 2

    return totalTokens, nil
}
```

### 2. 模型特定计数

不同模型有不同的计数方式：

```go
func getEncoder(model string) (*tiktoken.Tiktoken, error) {
    switch {
    case strings.HasPrefix(model, "gpt-4"):
        return tiktoken.EncodingForModel("gpt-4")
    case strings.HasPrefix(model, "gpt-3.5"):
        return tiktoken.EncodingForModel("gpt-3.5-turbo")
    case strings.HasPrefix(model, "claude"):
        return tiktoken.EncodingForModel("claude-2")
    default:
        return tiktoken.GetEncoding("cl100k_base")
    }
}
```

## 计费流程

### 1. 计费会话

```go
type BillingSession struct {
    UserId           int
    TokenId          int
    ChannelId        int
    ModelName        string
    PromptTokens     int
    CompletionTokens int
    TotalTokens      int
    Quota            int
    StartTime        time.Time
    EndTime          time.Time
}

func CreateBillingSession(c *gin.Context) *BillingSession {
    return &BillingSession{
        UserId:    c.GetInt("user_id"),
        TokenId:   c.GetInt("token_id"),
        ChannelId: c.GetInt("channel_id"),
        ModelName: c.GetString("original_model"),
        StartTime: time.Now(),
    }
}
```

### 2. 配额计算

```go
func CalculateQuota(session *BillingSession) int {
    // 获取模型定价
    pricing := model.GetModelPricing(session.ModelName)

    // 计算输入成本
    inputCost := float64(session.PromptTokens) * pricing.InputPrice / 1000000

    // 计算输出成本
    outputCost := float64(session.CompletionTokens) * pricing.OutputPrice / 1000000

    // 总成本（转换为配额单位）
    totalCost := inputCost + outputCost
    quota := int(totalCost * float64(common.QuotaPerUnit))

    return quota
}
```

### 3. 配额扣除

```go
func DeductQuota(session *BillingSession) error {
    // 计算配额
    quota := CalculateQuota(session)
    session.Quota = quota

    // 扣除用户配额
    err := model.DecreaseUserQuota(session.UserId, quota)
    if err != nil {
        return err
    }

    // 扣除令牌配额（如果不是无限配额）
    token, _ := model.GetTokenById(session.TokenId)
    if !token.UnlimitedQuota {
        err = model.DecreaseTokenQuota(session.TokenId, quota)
        if err != nil {
            return err
        }
    }

    // 增加渠道使用量
    err = model.IncreaseChannelUsedQuota(session.ChannelId, quota)
    if err != nil {
        return err
    }

    // 记录日志
    session.EndTime = time.Now()
    return model.RecordLog(session)
}
```

## 错误处理

### 1. 错误类型

```go
type OpenAIError struct {
    Message string `json:"message"`
    Type    string `json:"type"`
    Param   string `json:"param,omitempty"`
    Code    string `json:"code,omitempty"`
}

type OpenAIErrorWithStatusCode struct {
    Error      OpenAIError
    StatusCode int
}
```

### 2. 错误映射

渠道可以配置状态码映射，将上游错误码映射为标准错误码：

```json
{
  "400": 400,
  "401": 401,
  "429": 429,
  "500": 500,
  "503": 429
}
```

### 3. 自动禁用

当渠道连续失败时，系统会自动禁用该渠道：

```go
func CheckAndDisableChannel(channelId int, err error) {
    channel, _ := model.GetChannelById(channelId)

    // 检查是否启用自动禁用
    if channel.AutoBan == nil || *channel.AutoBan == 0 {
        return
    }

    // 检查错误类型
    if isAuthError(err) || isCriticalError(err) {
        // 立即禁用
        model.DisableChannel(channelId, "认证失败或严重错误")
    } else {
        // 增加失败计数
        failCount := incrementFailCount(channelId)
        if failCount >= 3 {
            model.DisableChannel(channelId, "连续失败3次")
        }
    }
}
```

## 性能优化

### 1. 连接池

```go
var httpClient *http.Client

func InitHttpClient() {
    transport := &http.Transport{
        MaxIdleConns:        100,
        MaxIdleConnsPerHost: 20,
        IdleConnTimeout:     90 * time.Second,
        DisableKeepAlives:   false,
    }

    httpClient = &http.Client{
        Transport: transport,
        Timeout:   120 * time.Second,
    }
}
```

### 2. 请求体缓存

对于重试场景，需要缓存请求体：

```go
func CacheRequestBody(c *gin.Context) {
    body, _ := io.ReadAll(c.Request.Body)
    c.Set("request_body", body)
    c.Request.Body = io.NopCloser(bytes.NewBuffer(body))
}

func GetCachedRequestBody(c *gin.Context) io.Reader {
    body, _ := c.Get("request_body")
    return bytes.NewBuffer(body.([]byte))
}
```

### 3. 并发控制

使用 gopool 进行并发控制：

```go
import "github.com/bytedance/gopkg/util/gopool"

gopool.Go(func() {
    // 异步任务
})
```

## 下一步阅读

- [04-渠道适配器开发.md](./04-渠道适配器开发.md) - 如何添加新的 AI 提供商
- [06-计费系统.md](./06-计费系统.md) - 详细的计费逻辑
- [07-监控和日志.md](./07-监控和日志.md) - 监控和日志系统
